{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# EminemNN Live Demo"
      ],
      "metadata": {
        "id": "BS5rHK0uaO-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data and models"
      ],
      "metadata": {
        "id": "7WfQxTpsacx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Pip installs\n",
        "!pip3 install pronouncing\n",
        "!pip3 install textstat\n",
        "!pip3 install markovify\n",
        "!pip install transformers\n",
        "\n",
        "# Import libraries\n",
        "import subprocess\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import random as rand\n",
        "import numpy as np\n",
        "import pronouncing\n",
        "import textstat\n",
        "import markovify\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from keras.utils import pad_sequences\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "# Load Eminem lyrics data\n",
        "dataFilePath = '/content/drive/MyDrive/ALL_eminem.txt'\n",
        "with open(dataFilePath, 'r') as file:\n",
        "  data = (file.read())\n",
        "eminemBars = data.split('\\n') # split lyrics dataset into bars\n",
        "tokeniser = tf.keras.preprocessing.text.Tokenizer(num_words=20000)\n",
        "tokeniser.fit_on_texts(eminemBars)\n",
        "\n",
        "# Load simple RNN model\n",
        "loaded_modelRNN = tf.keras.models.load_model('/content/drive/MyDrive/EminemNN_simpleRNNmodel.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYnKrrq7acTS",
        "outputId": "e9526dfa-77d3-48e9-b765-b72ed2c24cbc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pronouncing\n",
            "  Downloading pronouncing-0.2.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cmudict>=0.4.0\n",
            "  Downloading cmudict-1.0.13-py3-none-any.whl (939 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.3/939.3 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<6.0.0,>=5.10.1 in /usr/local/lib/python3.9/dist-packages (from cmudict>=0.4.0->pronouncing) (5.12.0)\n",
            "Collecting importlib-metadata<6.0.0,>=5.1.0\n",
            "  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata<6.0.0,>=5.1.0->cmudict>=0.4.0->pronouncing) (3.15.0)\n",
            "Building wheels for collected packages: pronouncing\n",
            "  Building wheel for pronouncing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pronouncing: filename=pronouncing-0.2.0-py2.py3-none-any.whl size=6251 sha256=a25a50fa0cf5ec9617d3166768f0d14068ee180c7b0a947bed58636866d9071e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/d4/c2/fb8c0e2009b75358874506ff2ce1ee79370b6ef5cf08922206\n",
            "Successfully built pronouncing\n",
            "Installing collected packages: importlib-metadata, cmudict, pronouncing\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.4.1\n",
            "    Uninstalling importlib-metadata-6.4.1:\n",
            "      Successfully uninstalled importlib-metadata-6.4.1\n",
            "Successfully installed cmudict-1.0.13 importlib-metadata-5.2.0 pronouncing-0.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting textstat\n",
            "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyphen\n",
            "  Downloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.14.0 textstat-0.7.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting markovify\n",
            "  Downloading markovify-0.9.4.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: markovify\n",
            "  Building wheel for markovify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markovify: filename=markovify-0.9.4-py3-none-any.whl size=18625 sha256=46dba58fd2ccd169d2da13e600dc05f543bb6299571f85d5bdfff2216b2286db\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/0a/ab/8727d219981e57e6036316dd2ec2037e61ccea0c016f7ae0c1\n",
            "Successfully built markovify\n",
            "Installing collected packages: unidecode, markovify\n",
            "Successfully installed markovify-0.9.4 unidecode-1.3.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple RNN for rap lyric generation\n"
      ],
      "metadata": {
        "id": "UoDOCdzlaS6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supplementary code"
      ],
      "metadata": {
        "id": "E7iovujSbKFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "markovModel = markovify.NewlineText(str(\"\\n\".join(eminemBars)), well_formed=False, state_size=3) # language model to create seed phrases\n",
        "def compareBars(bar, eminemBars):\n",
        "  \"\"\"\n",
        "  Compare the generated bar to each of Eminem's bars\n",
        "  \"\"\"\n",
        "  totalDist = 0\n",
        "  count = 0\n",
        "\n",
        "  for eb in eminemBars:\n",
        "    vectoriser = CountVectorizer()\n",
        "    barVec = vectoriser.fit_transform([bar, eb])\n",
        "\n",
        "    # Cosine distance\n",
        "    barArr = barVec.toarray()\n",
        "    dist = 1-pdist(barArr, 'cosine')[0]\n",
        "    if not math.isnan(dist):\n",
        "      totalDist += dist\n",
        "      count += 1\n",
        "  avDist = totalDist/count # lower score means more unique bars\n",
        "  return avDist\n",
        "\n",
        "def rateBar(bar, eminemBars, eminemReadability, eminemRhymeIdx):\n",
        "  \"\"\"\n",
        "  Calculate a rating for the generated bar based on readability, rhyme density and comparison to Eminem's bars\n",
        "  \"\"\"\n",
        "  readability = textstat.automated_readability_index(bar)\n",
        "  rhymeIdx = getRhymeDensity(bar)\n",
        "  comparison = compareBars(bar, eminemBars)\n",
        "\n",
        "  rating = (eminemReadability - readability) + (eminemRhymeIdx - rhymeIdx) + comparison # lower rating is better\n",
        "  return rating\n",
        "\n",
        "def getReadability(bars):\n",
        "  \"\"\"\n",
        "  Returns the average readability score for the given bars\n",
        "  \"\"\"\n",
        "  total = 0\n",
        "  count = len(bars)\n",
        "\n",
        "  for bar in bars:\n",
        "    total += textstat.automated_readability_index(bar)\n",
        "\n",
        "  averageReadability = total / count\n",
        "  return averageReadability\n",
        "\n",
        "def getRhymeDensity(bars):\n",
        "  \"\"\"\n",
        "  Returns the average rhyme density for the given bars\n",
        "  \"\"\"\n",
        "  totalSyllables = 0\n",
        "  rhymedSyllables = 0\n",
        "\n",
        "  for bar in bars:\n",
        "    for word in bar.split():\n",
        "      p = pronouncing.phones_for_word(word)\n",
        "      if len(p) == 0:\n",
        "        break\n",
        "      syllables = pronouncing.syllable_count(p[0])\n",
        "      totalSyllables += syllables\n",
        "      doesRhyme = False\n",
        "      for rhyme in pronouncing.rhymes(word):\n",
        "        if doesRhyme:\n",
        "          break\n",
        "        for idx, b in enumerate(bars):\n",
        "          if idx > 4:\n",
        "            break\n",
        "          if rhyme in b:\n",
        "            rhymedSyllables += syllables\n",
        "            doesRhyme = True\n",
        "            break\n",
        "  rhymeDensity = rhymedSyllables / totalSyllables\n",
        "  return rhymeDensity\n",
        "\n",
        "def generateBar(seedPhrase, model, barLen):\n",
        "  \"\"\"\n",
        "  Generates a bar based on seed phrase\n",
        "  \"\"\"\n",
        "  for i in range(barLen):\n",
        "    seedTokens = pad_sequences(tokeniser.texts_to_sequences([seedPhrase]), maxlen=29)\n",
        "    p = model.predict(seedTokens, verbose=0)\n",
        "    word = np.argmax(p, axis=1)[0]-1\n",
        "    seedPhrase += \" \" + str(list(tokeniser.word_index.items())[word][0])\n",
        "  return seedPhrase\n",
        "\n",
        "def generateRap(model, eminemBars, userPrompt, eminemReadability, eminemRhymeIdx, barLen=10, rapLen=5, minThreshold=-0.2, maxThreshold=0.2, attempts=1):\n",
        "  \"\"\"\n",
        "  Generates a rap\n",
        "  \"\"\"\n",
        "  rap = []\n",
        "  bars = 0\n",
        "  count = 0\n",
        "  potentialBars = []\n",
        "\n",
        "  while len(rap) < rapLen:\n",
        "    if len(rap)==0:\n",
        "      seedPhrase = userPrompt\n",
        "    else:\n",
        "      seedPhrase = markovModel.make_sentence(tries=100).split(\" \") # use Markov model to generate seed phrase\n",
        "      seedPhrase = \" \".join(seedPhrase[:3])\n",
        "    count += 1\n",
        "    bar = generateBar(seedPhrase, model, rand.randrange(4, barLen))\n",
        "    barRating = rateBar(bar, eminemBars, eminemReadability, eminemRhymeIdx) \n",
        "    potentialBars.append((barRating, bar))\n",
        "\n",
        "    if barRating <= maxThreshold and barRating >= minThreshold:\n",
        "      rap.append(bar)\n",
        "      bars += 1\n",
        "      count = 0\n",
        "      print(\"Generated Bar:\", bars, \"\\n\", bar)\n",
        "\n",
        "    if count >= attempts:\n",
        "      lowest = np.Infinity\n",
        "      bestBar = \"\"\n",
        "      for bar in potentialBars:\n",
        "        if bar[0] < lowest:\n",
        "          bestBar = bar[1]\n",
        "          potentialBars = []\n",
        "      \n",
        "      rap.append(bestBar)\n",
        "      bars += 1\n",
        "      count = 0\n",
        "      print(\"Generated Bar:\", bars, \"\\n\", bestBar)\n",
        "\n",
        "  return rap\n",
        "\n"
      ],
      "metadata": {
        "id": "31LB8XQBkHDm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate rap with simple RNN"
      ],
      "metadata": {
        "id": "KjloFLpxbGNJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNB6ozhAaOJ9",
        "outputId": "1ea01bce-c124-4c20-d446-788ec3b097c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a prompt for the rap: I love computer science\n",
            "\n",
            "Generating rap...\n",
            "Generated Bar: 1 \n",
            " I love computer science freeze fall dude back down there\n",
            "Generated Bar: 2 \n",
            " I breathe on you do me for me\n",
            "Generated Bar: 3 \n",
            " For all the feeling alone for you\n",
            "Generated Bar: 4 \n",
            " And just make what 8x mean hailie say eminem yeah\n",
            "Generated Bar: 5 \n",
            " I never meant back again baby baby boy i know why what\n",
            "\n",
            "Rap Generated with Simple RNN:\n",
            "I love computer science freeze fall dude back down there\n",
            "I breathe on you do me for me\n",
            "For all the feeling alone for you\n",
            "And just make what 8x mean hailie say eminem yeah\n",
            "I never meant back again baby baby boy i know why what\n",
            "\n"
          ]
        }
      ],
      "source": [
        "userPrompt = input(\"Enter a prompt for the rap: \")\n",
        "print(\"\\nGenerating rap...\")\n",
        "rap = generateRap(loaded_modelRNN, eminemBars, userPrompt, 2.9082144822041736, 0.3032329559883949) # Eminem readability and rhyme index pre-calculated to save time\n",
        "\n",
        "print(\"\\nRap Generated with Simple RNN:\")\n",
        "for line in rap:\n",
        "  print(line)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer model for rap lyric generation"
      ],
      "metadata": {
        "id": "Ik71w_H3aYl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supplementary code"
      ],
      "metadata": {
        "id": "Q1trgEUn5OFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_lyric(start: str, length: int, topk: int) -> list[str]:\n",
        "  length_flag = \"--length=\" + str(length)\n",
        "  result = subprocess.run(['python', '/content/drive/MyDrive/run_generation.py', '--model_type', 'gpt2', '--model_name_or_path', '/content/drive/MyDrive/emNN_finetuned', '--prompt', start, '--stop_token', '', '--k', '50', length_flag, '--num_return_sequences', str(topk)], capture_output=True)\n",
        "  result_str = result.stdout.decode('utf-8')\n",
        "  result_str = re.sub('=== GENERATED SEQUENCE 1 ===\\n', \"\", result_str)\n",
        "  result_str = re.sub('<EOS>', '', result_str)\n",
        "  result_str = re.sub('<BOS>', '', result_str)\n",
        "  result_list = re.split('=== GENERATED SEQUENCE \\d ===\\n', result_str)\n",
        "  return result_list"
      ],
      "metadata": {
        "id": "mbPTYJmj5QQw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate rap with GPT-2 transfomer"
      ],
      "metadata": {
        "id": "gjjp2vcQ8D3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lyrics_res = generate_lyric(userPrompt, 200, 1)\n",
        "print(lyrics_res[0].replace('\"', '\\n'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHQLqIRK57F-",
        "outputId": "ca8b7acf-aabf-44ba-dc64-f4b828b561fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love computer science and love writing.\n",
            "\n",
            " \n",
            "We need more people with computer science skills, because we want more talent.\n",
            " I said \n",
            "Yeah, you got a job, but don't let me get in your office.\n",
            " \n",
            "What the fuck? How the fuck are you supposed   on my plane? I'm in the wrong plane!\n",
            " I said \n",
            "Oh, no, no! I'm in the wrong plane!\n",
            " \n",
            "You're getting in your seat, you're on my plane! I'll take you to where you're supposed to be!\n",
            " But I'm not in the right plane.\n",
            " \n",
            "Oh no!\n",
            " \n",
            "Yeah, no!\n",
            " \n",
            "What the fuck are you supposed to know? You're not supposed to know!\n",
            "\n",
            " I don't mean \n",
            "I don't like it\n",
            " \n",
            "What the fuck do you say?\n",
            " \n",
            "Oh, my God!\n",
            " \n",
            "Oh no!\n",
            " \n",
            "You ain't got no brain! You ain't got no brain! You ain't got no brain! You ain't got no brain!\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}