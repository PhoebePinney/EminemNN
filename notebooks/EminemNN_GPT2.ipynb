{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Prepare and split the data"
      ],
      "metadata": {
        "id": "ILBwtTpbLQ8j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUmHo3yYTAsV",
        "outputId": "8f653d74-b0a6-4b9c-9e17-daf75fd6a2c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataFilePath = '/content/drive/MyDrive/ALL_eminem.txt'\n",
        "with open(dataFilePath, 'r') as file:\n",
        "  data = (file.read())"
      ],
      "metadata": {
        "id": "rN3kUYcYU7oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "#Remove the artist name of the top of the verses\n",
        "data = re.sub('\\[.*?\\]\\n', \"\", data) \n",
        "\n",
        "# split into verses\n",
        "data_songs = data.split('\\n\\n')"
      ],
      "metadata": {
        "id": "6js554D8Vp29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import floor\n",
        "train_val_loc = floor(len(data_songs)*0.7)\n",
        "val_test_loc = floor(len(data_songs)*0.9)\n",
        "train_data = data_songs[:train_val_loc]\n",
        "val_data = data_songs[train_val_loc:val_test_loc]\n",
        "test_data = data_songs[val_test_loc:]\n",
        "\n",
        "print(\"train_verses =\", len(train_data))\n",
        "print(\"val_verses =\", len(val_data))\n",
        "print(\"test_verses =\", len(test_data))\n",
        "print(\"total verses =\", len(data_songs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0vj2MVjV0J_",
        "outputId": "2fb3fb2d-a447-4d40-a4c9-0e371bbd6743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_verses = 1203\n",
            "val_verses = 344\n",
            "test_verses = 172\n",
            "total verses = 1719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_gpt2_in_text(verse_list: list, path: str):\n",
        "  data = \"\"\n",
        "  for verse in verse_list:\n",
        "    verse = verse.strip()\n",
        "    verse = re.sub(\"\\s\", \" \", verse) # replace all types of spaces like tabs and so on with a normal space \n",
        "    bos_token = ''\n",
        "    eos_token = ''\n",
        "    data += bos_token + ' ' + verse + ' ' + eos_token + '\\n'\n",
        "  file = open(path, 'w')\n",
        "  file.write(data)\n",
        "  \n",
        "to_gpt2_in_text(train_data, \"train_data.txt\")\n",
        "to_gpt2_in_text(val_data, \"val_data.txt\")\n",
        "to_gpt2_in_text(test_data, \"test_data.txt\")"
      ],
      "metadata": {
        "id": "pucbAztBXNPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation of necessary packages"
      ],
      "metadata": {
        "id": "7IwFPtfALgy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCX8FSWubgxH",
        "outputId": "bdfb69d6-48e0-4efd-d511-ee54f5422671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gee9Q2WGgEcQ",
        "outputId": "bb79b000-2f5d-4dd4-e860-c3944561388b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-vuqlu7cn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-vuqlu7cn\n",
            "  Resolved https://github.com/huggingface/transformers to commit 4e1522d65ac5ff5a4a90dc2a223fc20078a85744\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (3.11.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (23.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (0.14.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.29.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.29.0.dev0) (2023.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.29.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.29.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.29.0.dev0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.29.0.dev0) (3.4)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.29.0.dev0-py3-none-any.whl size=6990209 sha256=a262fc36d9da216377c9d0fbc3f82e6d8c4fe0b6193df4c783ecb0dcc1c60f51\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sermne3i/wheels/14/a0/7b/8f6b25ba4110aa215fcb8d6aedd6cd4f9b9b6619190999ac2b\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.28.1\n",
            "    Uninstalling transformers-4.28.1:\n",
            "      Successfully uninstalled transformers-4.28.1\n",
            "Successfully installed transformers-4.29.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIWO8xeKiQT7",
        "outputId": "ee5b7a02-a474-47c5-e133-1538cd5cc558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.1)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.5.3)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.4/269.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSmgVLn2inWy",
        "outputId": "ff70a9ee-a070-482e-f55c-15fe84bd7de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/215.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (16.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.4.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.4.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine tuning of model"
      ],
      "metadata": {
        "id": "tRHuxWBlRcgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python '/content/drive/MyDrive/run_clm.py' \\\n",
        "  --output_dir='/content/drive/MyDrive/emNN_finetuned'\\\n",
        "  --model_type=gpt2 \\\n",
        "  --model_name_or_path='gpt2' \\\n",
        "  --do_train \\\n",
        "  --train_file='train_data.txt'\\\n",
        "  --do_eval \\\n",
        "  --validation_file='val_data.txt'\\\n",
        "  --per_device_train_batch_size=2 \\\n",
        "  --per_device_eval_batch_size=2 \\\n",
        "  --learning_rate 5e-5 \\\n",
        "  --num_train_epochs=5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e37gh-Xp4R8",
        "outputId": "bcbea2d3-05f1-4d42-d841-7d5a9da0319e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7f493cfc74c0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/jax/_src/lib/__init__.py\", line 97, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n",
            "2023-04-26 11:17:31.105474: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "04/26/2023 11:17:34 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n",
            "Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-9518d178f7da0953/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2...\n",
            "Downloading data files: 100% 2/2 [00:00<00:00, 10498.88it/s]\n",
            "Extracting data files: 100% 2/2 [00:00<00:00, 1836.79it/s]\n",
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-9518d178f7da0953/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2. Subsequent calls will reuse this data.\n",
            "100% 2/2 [00:00<00:00, 766.92it/s]\n",
            "Running tokenizer on dataset:   0% 0/1203 [00:00<?, ? examples/s][WARNING|tokenization_utils_base.py:3581] 2023-04-26 11:17:38,049 >> Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
            "[WARNING|run_clm.py:389] 2023-04-26 11:17:38,050 >> ^^^^^^^^^^^^^^^^ Please ignore the warning above - this long input will be chunked into smaller bits before being passed to the model.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "{'train_runtime': 263.7465, 'train_samples_per_second': 2.919, 'train_steps_per_second': 1.46, 'train_loss': 4.397508497362013, 'epoch': 5.0}\n",
            "100% 385/385 [04:23<00:00,  1.46it/s]\n",
            "***** train metrics *****\n",
            "  epoch                    =        5.0\n",
            "  train_loss               =     4.3975\n",
            "  train_runtime            = 0:04:23.74\n",
            "  train_samples            =        154\n",
            "  train_samples_per_second =      2.919\n",
            "  train_steps_per_second   =       1.46\n",
            "100% 22/22 [00:04<00:00,  4.42it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        5.0\n",
            "  eval_loss               =     3.7513\n",
            "  eval_runtime            = 0:00:05.20\n",
            "  eval_samples            =         44\n",
            "  eval_samples_per_second =      8.461\n",
            "  eval_steps_per_second   =      4.231\n",
            "  perplexity              =    42.5757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare gpt2 and the finetuned gpt2 on the unseen test set"
      ],
      "metadata": {
        "id": "JSOJLP293Yn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/run_clm.py --output_dir='/content/drive/MyDrive/emNN_finetuned_eval' --model_type='gpt2' --model_name_or_path='/content/drive/MyDrive/emNN_finetuned' --do_eval --validation_file='test_data.txt' --per_device_eval_batch_size=2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6snndYTD6X1r",
        "outputId": "68e987de-2640-4616-c6c2-d72c6c358c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-26 10:54:46.186071: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "04/26/2023 10:54:50 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n",
            "Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-30b327259ed38b6f/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2...\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 5309.25it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 820.64it/s]\n",
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-30b327259ed38b6f/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 806.60it/s]\n",
            "100% 14/14 [00:02<00:00,  5.33it/s]\n",
            "***** eval metrics *****\n",
            "  eval_loss               =     3.8621\n",
            "  eval_runtime            = 0:00:03.25\n",
            "  eval_samples            =         27\n",
            "  eval_samples_per_second =      8.303\n",
            "  eval_steps_per_second   =      4.305\n",
            "  perplexity              =    47.5646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_clm.py --output_dir='/content/drive/MyDrive/eminem_gpt2_eval' --model_type='gpt2' --model_name_or_path='gpt2' --do_eval --validation_file='test_data.txt' --per_device_eval_batch_size=2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmL_e12449Ah",
        "outputId": "ccc3411a-88b5-4005-9e2e-ef5775d2d731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-25 19:34:20.292802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "04/25/2023 19:34:24 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-24fe4eec150f3ab6/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2...\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 5127.51it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1007.28it/s]\n",
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-24fe4eec150f3ab6/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 851.64it/s]\n",
            "100% 14/14 [00:02<00:00,  5.23it/s]\n",
            "***** eval metrics *****\n",
            "  eval_loss               =               121.334\n",
            "  eval_runtime            =            0:00:03.28\n",
            "  eval_samples            =                    27\n",
            "  eval_samples_per_second =                 8.225\n",
            "  eval_steps_per_second   =                 4.265\n",
            "  perplexity              = 4.951115699746246e+52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Massive improvement in perplexity after fine tuning\n",
        "\n"
      ],
      "metadata": {
        "id": "wwd6zchoJore"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate from prompt"
      ],
      "metadata": {
        "id": "AeQxnPUV8S9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python '/content/drive/MyDrive/run_generation.py' \\\n",
        "  --model_type gpt2 \\\n",
        "  --model_name_or_path '/content/drive/MyDrive/emNN_finetuned' \\\n",
        "  --prompt \"computer science is love computer science is life\" \\\n",
        "  --stop_token \"\" \\\n",
        "  --k 50 \\\n",
        "  --length=500 \\\n",
        "  --num_return_sequences 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBpnLnp-8EGS",
        "outputId": "46f84660-f848-4425-a386-a6c2120df291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-26 11:29:57.245767: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "04/26/2023 11:29:58 - WARNING - __main__ - device: cuda, n_gpu: 1, 16-bits training: False\n",
            "04/26/2023 11:30:05 - INFO - __main__ - Namespace(model_type='gpt2', model_name_or_path='/content/drive/MyDrive/emNN_finetuned', prompt='computer science is love computer science is life', length=500, stop_token='', temperature=1.0, repetition_penalty=1.0, k=50, p=0.9, prefix='', padding_text='', xlm_language='', seed=42, no_cuda=False, num_return_sequences=5, fp16=False, device=device(type='cuda'), n_gpu=1)\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "computer science is love computer science is life Computer science is sex appeal computer science is all you need to start a career for anyone But you're a little too young to have had that thought and maybe you're wrong But you've been thinking in the wrong way for too long And sometimes your thoughts get stuck, you can't shake them Your little genius is just so amazing You don't know when you want to start writing But if you can, just try to keep it in check So if you can, just try to keep it in check Now if you can, just try to keep it in check So if you can, just try to keep it in check Now if you can, just try to keep it in check \n",
            " This is not your life \n",
            " I'm not your life \n",
            " You're the only one I can't take You're the only one I can't take \n",
            " I'm not your life I'm afraid to get hurt And to see a sick girl, I'm afraid to be alone \n",
            " \n",
            " Now what about me? \n",
            " Now what about me? \n",
            " Now what about me? \n",
            " I'm sorry I hurt you \n",
            " Now what about me? \n",
            " Now what about me? \n",
            " My life's just a tool to try to help You're my life, but it's hard enough to even be accepted I'm sorry I hurt you \n",
            " My life's just a tool to try to help You're my life, but it's hard enough to even be accepted I'm sorry I hurt you \n",
            " \n",
            " This is not your life I'm afraid to get hurt And to see a sick girl, I'm afraid to be alone \n",
            " I'm not your life, I'm afraid to be alone \n",
            " I'm sorry I hurt you \n",
            " My life's just a tool to try to help You're my life, but it's hard enough to even be accepted I'm sorry I hurt you \n",
            " \n",
            " Now what about me? \n",
            " Now what about me? \n",
            " My life's just a tool to try to help You're my life, but it's hard enough to even be accepted I'm sorry I hurt you \n",
            " I'm sorry I hurt you \n",
            " My life's just a tool to try to help You're my life, but it's hard enough to even be accepted I'm sorry I hurt you \n",
            " \n",
            " Now what about me? \n",
            " Now what about me? \n",
            " My life's just a tool to try\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "computer science is love computer science is life hacking computer science is romance computer science is romantic girl computer science is romantically attractive computer science is romance, romance is like an open-air swimming pool with all of your friends, is that why you're so attracted? This is so much love Computer science is love Computer science is love You are so attracted, so excited to meet you, we can have sex, you can get married, you're crazy, we can get divorced and it's OK, and I can't wait for you to get your ass and your brain implants You're my life force, your life force, my strength and my freedom You are my medicine, your medicine is my medicine My life will take care of itself, your life will take care of itself, your life will take care of itself, you'll be OK If you keep on trying, you'll end up with a bad case of HRT You may end up losing a job or losing a friend And your life will take care of itself And your life will take care of itself You'll end up losing a job or losing a friend And your life will take care of itself And you'll end up losing a friend You'll end up losing a friend, it's time to break up And to do that, you must lose control You must lose control of yourself and you must lose control of your body and your mind You must destroy yourself and you must destroy your mind And destroy yourself and you must destroy your body and your mind So, you will never be alone, and you will never be alone But you'll never find someone who will never find you, that's why I say stay on and get your ass and your brain implants I'm the antidote to your evil, the antidote to your evil, the antidote to your evil, I'm the antidote to your evil, the antidote to your evil, that's why you're so attracted, so excited to meet you, we can have sex, you can get married, you're crazy, we can get divorced and it's OK, and I can't wait for you to get your ass and your brain implants You're my life force, your life force, my strength and my freedom You are my medicine, your medicine is my medicine My life will take care of itself, your life will take care of itself, your life will take care of itself And your life will take care of itself and you'll end up losing a job or losing a friend And your life will take care of itself and you'll end up\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "computer science is love computer science is life\n",
            "\n",
            "Everybody wants to quit this thing, and then I have to leave it\n",
            "\n",
            "I guess the only way to make a difference is for me to start over\n",
            "\n",
            "What you do, how you do What you do, how you do, how you do, how you do, why you do What you do, how you do, how you do\n",
            "\n",
            "What you do, how you do What you do, how you do What you do, how you do, how you do, why you do What you do, how you do, how you do, why you do\n",
            " You do the things you do, you do the things you do And now you're in my house \n",
            " I do all the things I do, I do all the things I do (not kidding) I do all the things I do, I do all the things I do (not kidding) \n",
            " (haha) But I'm back with more guns than I ever did, I'm back with more guns than I ever did, and now I'm at a gun booth And my conscience tells me to go shoot the crap out of him! I'm back! I'm back! \n",
            " (aah!) And if I don't give him my money (in my opinion) And if I don't give him my money (in my opinion) And if I don't give him my money (in my opinion) And if I do, then I'll go and sell it all to his people \n",
            " I do what I do what I do, I do what I do, I do what I do, I do what I do, I do what I do, \n",
            " So please tell me I can do what I do, I'm done with this shit I did for the last couple of years (I'm starting to get it) And if I don't give it to his friends, I'll never get it Back, back up, back up, back up \n",
            " If I don't give him my money, and if I don't give him my money, and if I don't give him my money, and if I don't give him my money, I'm done with this shit I did for the last couple of years (I'm starting to get it) And if I don't give him my money, and if I don't give him my money, and if I don't give him my money, \n",
            " And if I don't give him\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "computer science is love computer science is life hacking, is it really possible? It's not hard to find people who've never even <BOS>  had a computer science degree or not. But it can be hard to find people who've never had a computer science degree or not. But it can be hard to find people who've never had a computer science degree or not.\n",
            "\n",
            "In the world of science, it is usually easy to get lost in the ocean, but that's not usually the case. <BOS>'s not easy to get lost in the ocean, but that's not usually the case.\n",
            " You may think that your life is too short to pursue this, but in fact you're going to find it. You may think that your life is too short to pursue this, but in fact you're going to find it. You may think that your life is too short to pursue this, but in fact you're going to find it.\n",
            " My life ain't short. I can tell you, I'm not short. I can tell you, I'm not short. I can tell you, I'm not short. I can tell you, I'm not short. I can tell you, I'm not short. I can tell you, I'm not short.\n",
            " I'm the light of the day, the light of the day, the light of the day. I'm the light of the day, the light of the day, the light of the day. I'm the light of the day, the light of the day, the light of the day. But I'll never forget the day of my arrest, the day that was my only crime. That I was convicted of murder, and the verdict had been overturned. It was my only crime to murder my neighbor; a crime that never occurred. But the victim had no means to prove, but he'd have had to do it anyway. That's why the verdict was overturned, that's why the crime was reversed. That's why my criminal record was overturned. That's why I was placed in jail for no reason. But now I'm back. You are right. I'm going home to my mom, and I'm going home to my mother and I'm going home to my mother's. The only thing I can do is tell you my whole story. And it will be about your life, your life, and the life of my daughter. And just as my daughter is my life and my life's, my daughter is mine. And\n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "computer science is love computer science is life (no pun intended) computer science is music (but, you know, this is what the fucking music is supposed to be, right? Like the game that you're supposed to try and make it look like a computer) computer science is everything (no pun intended) computers are your friends (yeah, it's nice to see the love in you, but I guess it's like I'm just trying to get the hell out of you) You're the best at what you do (yeah, I know, you are) I'm the only one in the world who can make fun of a person who does not deserve it (no pun intended) I'm the only one who can see, hear, hear, hear you try and find the source (no pun intended) You can just as easily be your friend with the help of a computer (yeah, I know, you are) I'm the only one that can give you any ideas (no pun intended) And you know I know too, I know too, I know too (no pun intended) And I'm still in it, it's a fact (yeah, I can be the greatest) And I'm still in it (no pun intended) And I'm still in it (no pun meant) And I'm still in it (no pun intended) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I'm still in it (no pun meant) And I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapping it into a function"
      ],
      "metadata": {
        "id": "1_l6C0H_Ln6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "def generate_lyric(start: str, length: int, topk: int) -> list[str]:\n",
        "  length_flag = \"--length=\" + str(length)\n",
        "  result = subprocess.run(['python', '/content/drive/MyDrive/run_generation.py', '--model_type', 'gpt2', '--model_name_or_path', '/content/drive/MyDrive/emNN_finetuned', '--prompt', start, '--stop_token', '', '--k', '50', length_flag, '--num_return_sequences', str(topk)], capture_output=True)\n",
        "  result_str = result.stdout.decode('utf-8')\n",
        "  result_str = re.sub('=== GENERATED SEQUENCE 1 ===\\n', \"\", result_str)\n",
        "  result_str = re.sub('<EOS>', '', result_str)\n",
        "  result_str = re.sub('<BOS>', '', result_str)\n",
        "  result_list = re.split('=== GENERATED SEQUENCE \\d ===\\n', result_str)\n",
        "  return result_list\n"
      ],
      "metadata": {
        "id": "ov6EesLFNjXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lyrics_res = generate_lyric(\"Man don't do this\", 200, 10)"
      ],
      "metadata": {
        "id": "qTqpKBb9Oe_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lyrics_res[0].replace('\"', '\\n'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jiz9JHBNsex",
        "outputId": "a3dbda79-867a-41f7-d3e2-7d1350d0a7c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Man don't do this for you no more\n",
            "\n",
            " \n",
            "Stop making me look like an idiot.\n",
            "\n",
            " \n",
            "I'm on my own when it comes to my kids. My brain is always full of crap\n",
            "\n",
            " \n",
            "What the fuck? I'm acting different than a teenager\n",
            "\n",
            " \n",
            "It was my mother's fault. She tried to stop us when we were kids and we grew up with the opposite traits\n",
            "\n",
            " \n",
            "I'm from the block and she said 'Look at my kid, he's not behaving as a normal kid.'\n",
            "\n",
            " \n",
            "You wanna think that I'm retarded?\n",
            " \n",
            "No.\n",
            "\n",
            " \n",
            "Shut up, you can't get your butt kicked!\n",
            " \n",
            "I'm not retarded! I'm just mentally retarded!\n",
            "\n",
            " \n",
            "I'm a kid with no sense of humor and no taste in things\n",
            "\n",
            " \n",
            "That's why I never give a fuck.\n",
            " \n",
            "It ain't my fault that you've been treated worse than me\n",
            "\n",
            " \n",
            "Look at these pictures of my brain! What is it you think I\n",
            "\n"
          ]
        }
      ]
    }
  ]
}